{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ADS509 Final Project: News Source Classification and Topic Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Matt Ammirati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Project Overview </h3> - Predict whether an article comes from Fox news or CNN and analyze major discussion topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mammajamma/Projects/ADS509Final/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load API key securely\n",
    "config_path = os.path.join(\"..\", \"config.json\")\n",
    "\n",
    "with open(config_path) as f:\n",
    "    api_key = json.load(f)[\"newsapi_key\"]\n",
    "\n",
    "print(\"API key loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Collection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_articles(source, query=None, from_days=7, page_size=100, max_pages=3):\n",
    "    \"\"\"\n",
    "    Fetch recent articles from a given source using NewsAPI.\n",
    "    \n",
    "    Args:\n",
    "        source (str): The news source (e.g. 'cnn' or 'fox-news')\n",
    "        query (str): Optional keyword to filter articles\n",
    "        from_days (int): How many days back to pull articles\n",
    "        page_size (int): Number of results per page (max 100)\n",
    "        max_pages (int): How many pages to fetch\n",
    "    \"\"\"\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "    all_articles = []\n",
    "\n",
    "    from_date = (datetime.now() - timedelta(days=from_days)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        params = {\n",
    "            \"sources\": source,\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"pageSize\": page_size,\n",
    "            \"page\": page,\n",
    "            \"apiKey\": api_key,\n",
    "            \"language\": \"en\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get(\"status\") != \"ok\":\n",
    "            print(f\"Error fetching {source} page {page}: {data.get('message')}\")\n",
    "            break\n",
    "\n",
    "        articles = data.get(\"articles\", [])\n",
    "        if not articles:\n",
    "            break\n",
    "\n",
    "        all_articles.extend(articles)\n",
    "\n",
    "    print(f\"Retrieved {len(all_articles)} articles from {source}.\")\n",
    "    return pd.DataFrame(all_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching cnn page 2: You have requested too many results. Developer accounts are limited to a max of 100 results. You are trying to request results 100 to 200. Please upgrade to a paid plan if you need more results.\n",
      "Retrieved 100 articles from cnn.\n",
      "Error fetching fox-news page 2: You have requested too many results. Developer accounts are limited to a max of 100 results. You are trying to request results 100 to 200. Please upgrade to a paid plan if you need more results.\n",
      "Retrieved 100 articles from fox-news.\n"
     ]
    }
   ],
   "source": [
    "cnn_df = fetch_articles(\"cnn\", max_pages=3)\n",
    "fox_df = fetch_articles(\"fox-news\", max_pages=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Descriptive Statistics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 200\n",
      "CNN articles: 100\n",
      "Fox News articles: 100\n",
      "\n",
      "Missing values per column:\n",
      "source           0\n",
      "author         101\n",
      "title            0\n",
      "description      0\n",
      "url              0\n",
      "urlToImage       0\n",
      "publishedAt      0\n",
      "content          0\n",
      "label            0\n",
      "dtype: int64\n",
      "\n",
      "--- Descriptive Stats ---\n",
      "count    200.000000\n",
      "mean      75.475000\n",
      "std        9.242646\n",
      "min       46.000000\n",
      "25%       68.750000\n",
      "50%       74.000000\n",
      "75%       81.250000\n",
      "max      101.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Average word count by source:\n",
      "label\n",
      "CNN    79.15\n",
      "Fox    71.80\n",
      "Name: word_count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Live updates: Israeli hostage release from Gaz...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>DEVELOPING: HOSTAGES RELEASED</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Stock futures rise after Trump hints at backin...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Mark Sanchez booked and released from custody,...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>James Franklin fired as Penn State head coach ...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Diane Keaton was a pioneer for modern women, b...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN</td>\n",
       "      <td>More than half of CDC staffers recently fired ...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Hamas asserts control in Gaza and targets alle...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNN</td>\n",
       "      <td>South Carolina bar shooting: 4 people killed, ...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Texas Tech head coach pleads with tortilla-thr...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                              title  word_count\n",
       "0   CNN  Live updates: Israeli hostage release from Gaz...          63\n",
       "1   CNN                      DEVELOPING: HOSTAGES RELEASED          72\n",
       "2   CNN  Stock futures rise after Trump hints at backin...          80\n",
       "3   CNN  Mark Sanchez booked and released from custody,...          70\n",
       "4   CNN  James Franklin fired as Penn State head coach ...          74\n",
       "5   CNN  Diane Keaton was a pioneer for modern women, b...          65\n",
       "6   CNN  More than half of CDC staffers recently fired ...          76\n",
       "7   CNN  Hamas asserts control in Gaza and targets alle...          75\n",
       "8   CNN  South Carolina bar shooting: 4 people killed, ...          73\n",
       "9   CNN  Texas Tech head coach pleads with tortilla-thr...          78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine both sources before cleaning for descriptive stats\n",
    "cnn_df[\"label\"] = \"CNN\"\n",
    "fox_df[\"label\"] = \"Fox\"\n",
    "raw_df = pd.concat([cnn_df, fox_df], ignore_index=True)\n",
    "\n",
    "# Basic counts\n",
    "print(\"Total articles:\", len(raw_df))\n",
    "print(\"CNN articles:\", len(cnn_df))\n",
    "print(\"Fox News articles:\", len(fox_df))\n",
    "\n",
    "# Null values per column\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(raw_df.isnull().sum())\n",
    "\n",
    "# Combine text for simple length stats\n",
    "raw_df[\"combined_text\"] = (\n",
    "    raw_df[\"title\"].fillna(\"\") + \" \" +\n",
    "    raw_df[\"description\"].fillna(\"\") + \" \" +\n",
    "    raw_df[\"content\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Calculate article lengths\n",
    "raw_df[\"word_count\"] = raw_df[\"combined_text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Summary stats\n",
    "print(\"\\n--- Descriptive Stats ---\")\n",
    "print(raw_df[\"word_count\"].describe())\n",
    "\n",
    "# Grouped by source\n",
    "print(\"\\nAverage word count by source:\")\n",
    "print(raw_df.groupby(\"label\")[\"word_count\"].mean())\n",
    "\n",
    "# Quick preview\n",
    "raw_df[[\"label\", \"title\", \"word_count\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Cleaning</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EDA</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
